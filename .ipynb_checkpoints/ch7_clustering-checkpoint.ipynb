{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "movies_df = pd.read_csv('output/tmdb_5000_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract id from json before compute similarity, return a list\n",
    "def extract_json(df, label, row):\n",
    "    ids = []\n",
    "    if df.loc[row, label] != None:\n",
    "        items = json.loads(df.loc[row, label])\n",
    "    else:\n",
    "        return ids\n",
    "    for item in items:\n",
    "        # for production_countries, not numeric ids\n",
    "        if label == 'production_countries':\n",
    "            ids.append(item['iso_3166_1'])\n",
    "        elif label == 'spoken_languages':\n",
    "            ids.append(item['iso_639_1'])\n",
    "        else:\n",
    "            ids.append(item['id'])\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### discarded the text columns like title and  overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.drop(columns = ['title', 'original_title', 'original_language', 'overview'])\n",
    "# test data\n",
    "movies_df = movies_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 types of data in this dataset:\n",
    "1. ID\n",
    "2. Numeric: col = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "3. Json: col = ['cast', 'crew', 'genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']\n",
    "4. Date: col = ['release_date']\n",
    "##### how to compute the similarity?\n",
    "1. Numeric: The number\n",
    "2. Json: by counting the number of same elements in one dimension\n",
    "3. Release Date: by substracting the date\n",
    "After getting numbers, it is needed to normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget\n",
      "popularity\n",
      "revenue\n",
      "runtime\n",
      "vote_average\n",
      "vote_count\n",
      "cast\n",
      "crew\n",
      "genres\n",
      "keywords\n",
      "production_companies\n",
      "production_countries\n",
      "spoken_languages\n",
      "release_date\n"
     ]
    }
   ],
   "source": [
    "num_col = ['budget', 'popularity', 'revenue', 'runtime', 'vote_average', 'vote_count']\n",
    "json_col = ['cast', 'crew', 'genres', 'keywords', 'production_companies', 'production_countries', 'spoken_languages']\n",
    "date_col = ['release_date']\n",
    "\n",
    "columns = {}\n",
    "for i in num_col:\n",
    "    columns[i] = 'numeric'\n",
    "for i in json_col:\n",
    "    columns[i] = 'json'\n",
    "for i in date_col:\n",
    "    columns[i] = 'date'\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How to normalize the similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'budget': 365000000,\n",
       " 'popularity': 721.829249,\n",
       " 'revenue': 2787965087,\n",
       " 'runtime': 103.0,\n",
       " 'vote_average': 3.3999999999999995,\n",
       " 'vote_count': 13718,\n",
       " 'cast': 149,\n",
       " 'crew': 429,\n",
       " 'genres': 5,\n",
       " 'keywords': 31,\n",
       " 'production_companies': 10,\n",
       " 'production_countries': 3,\n",
       " 'spoken_languages': 8,\n",
       " 'release_date': 7676}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build similarity matrix\n",
    "# normalize the similarity value of each pair by 1-(A-B)/range(col) or A.intersection(B)/range(len(one cell))\n",
    "# {col: type of col}\n",
    "columns = {'budget': 'numeric',\n",
    " 'popularity': 'numeric',\n",
    " 'revenue': 'numeric',\n",
    " 'runtime': 'numeric',\n",
    " 'vote_average': 'numeric',\n",
    " 'vote_count': 'numeric',\n",
    " 'cast': 'json',\n",
    " 'crew': 'json',\n",
    " 'genres': 'json',\n",
    " 'keywords': 'json',\n",
    " 'production_companies': 'json',\n",
    " 'production_countries': 'json',\n",
    " 'spoken_languages': 'json',\n",
    " 'release_date': 'date'}\n",
    "\n",
    "\n",
    "# initialize similarity matrix\n",
    "simatrix = np.full((len(movies_df), len(movies_df)), None)\n",
    "\n",
    "# compute normalize base (range) for each column {column: denom}\n",
    "denom = {}\n",
    "for col in columns.keys():\n",
    "    tag = columns[col]\n",
    "    if tag == 'numeric':\n",
    "        denom[col] = movies_df[col].max() - movies_df[col].min()\n",
    "    if tag == 'json':\n",
    "        json_len = []\n",
    "        for i in range(len(movies_df)):\n",
    "            json_len.append(len(extract_json(movies_df, col, i)))\n",
    "        # compute range of len of the json object\n",
    "        denom[col] = max(json_len) - min(json_len)\n",
    "    if tag == 'date':\n",
    "        # compute the range of the date\n",
    "        max_date = datetime.strptime(movies_df[col].max(), '%Y-%m-%d').date()\n",
    "        min_date = datetime.strptime(movies_df[col].min(), '%Y-%m-%d').date()\n",
    "        denom[col] = (max_date - min_date).days\n",
    "denom            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute range(col) or avg(len(one cell))\n",
    "def comp_similarity(df, row_i, row_j, col):\n",
    "    tag = columns[col]\n",
    "    # for numeric columns\n",
    "    if tag == 'numeric':\n",
    "        # get row_i and row_j\n",
    "        num_i = movies_df.loc[row_i, col]\n",
    "        num_j = movies_df.loc[row_j, col]\n",
    "        # return normalized similarity\n",
    "        return 1 - abs(num_i - num_j)/denom[col]\n",
    "        \n",
    "    # for json column\n",
    "    if tag == 'json':\n",
    "        # extract row1\n",
    "        id_i = extract_json(movies_df, col, row_i)\n",
    "        # extract row2\n",
    "        id_j = extract_json(movies_df, col, row_j)\n",
    "        # compute similarity of this feature\n",
    "        sim_json = len(set(id_i).intersection(set(id_j)))\n",
    "        # return normalized similarity\n",
    "        return sim_json/denom[col]\n",
    "    \n",
    "    # for date column\n",
    "    if tag == 'date':\n",
    "        # get row_i and row_j\n",
    "        date_i = datetime.strptime(movies_df.loc[row_i, col], '%Y-%m-%d').date()\n",
    "        date_j = datetime.strptime(movies_df.loc[row_j, col], '%Y-%m-%d').date()\n",
    "        # return normalized similarity\n",
    "        return 1 - abs((date_i - date_j).days)/denom[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/output/simatrix.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1f61b42a12b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# dump the matrix into a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/output/simatrix.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         )\n\u001b[0;32m-> 3228\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             )\n\u001b[1;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/output/simatrix.csv'"
     ]
    }
   ],
   "source": [
    "# compute matrix\n",
    "# for every combination of rows\n",
    "for i in range(len(movies_df)-1):\n",
    "    for j in range(i+1, len(movies_df)):\n",
    "        sim_all  = 0\n",
    "        # for every feature\n",
    "        for col in columns.keys():\n",
    "            # compute normalized similarity of this feature\n",
    "            sim_col = comp_similarity(movies_df, i, j, col)\n",
    "            # combine similarity from each feature (now using add, can consider more complicated methods)\n",
    "            sim_all += sim_col          \n",
    "        # put sim_all into matrix\n",
    "        simatrix[i][j] = sim_all\n",
    "\n",
    "# dump the matrix into a file\n",
    "pd.DataFrame(simatrix).to_csv(\"output/simatrix.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
