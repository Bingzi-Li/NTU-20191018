{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>cast_0</th>\n",
       "      <th>director</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>company_0</th>\n",
       "      <th>country</th>\n",
       "      <th>cast_num</th>\n",
       "      <th>crew_num</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  cast_0  director  genre_0  company_0  country  cast_num  \\\n",
       "0         0       0         0        0          0        0         3   \n",
       "1         0       1         1        1          1        0         1   \n",
       "2         0       2         2        0          2        1         3   \n",
       "3         0       3         3        0          3        0         3   \n",
       "4         0       4         4        0          1        0         1   \n",
       "\n",
       "   crew_num  popularity  \n",
       "0         3         1.0  \n",
       "1         2         1.0  \n",
       "2         3         1.0  \n",
       "3         3         1.0  \n",
       "4         3         1.0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "# import the vectorized data\n",
    "df = pd.read_csv(\"chp5_classifiers/vector_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popular:  2393\n",
      "not popular:  2397\n"
     ]
    }
   ],
   "source": [
    "pop = len([x for x in df['popularity'] if x == 1.0])\n",
    "print(\"popular: \", pop)\n",
    "print(\"not popular: \", len(df) - pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Self-defined Metrics\n",
    "\n",
    "## nominal and ordinal attributes\n",
    "\n",
    "We have both nominal and ordinal attributes in the vectors.<br>\n",
    "Similarity:\n",
    "1. for nominal attribute, s = 1 if p == q, s = 0 if p != q\n",
    "2. for ordinal attribute, s = 1 - abs(p - q)/(n - 1)\n",
    "3. n: range of the mapping, in our case, n = 4\n",
    "<br> \n",
    "This takes much longer time to compute. The difference is very little. In consideration of simplicity, we choose to use <b>SMC</b> to compute the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for developing purpose\n",
    "df = df.head(200)\n",
    "\n",
    "columns = ['language', 'cast_0', 'director', 'genre_0', 'company_0', 'country', 'cast_num', 'crew_num']\n",
    "n = 4\n",
    "\n",
    "# similarity matrix\n",
    "simatrix = np.zeros((len(df), len(df)))\n",
    "# distance matrix\n",
    "dismatrix = np.zeros((len(df), len(df)))\n",
    "\n",
    "def metrics(df):\n",
    "    # for each row combination\n",
    "    for i in range(len(df) - 1):\n",
    "        for j in range(i + 1, len(df)):\n",
    "            # similarity vector of p and q\n",
    "            s = []\n",
    "            # nominal\n",
    "            for col in columns[:6]:\n",
    "                p = df.loc[i, col]\n",
    "                q = df.loc[j, col]\n",
    "                if p == q:\n",
    "                    s.append(1)\n",
    "                else:\n",
    "                    s.append(0)\n",
    "            # ordinal\n",
    "            for col in columns[6:]:\n",
    "                p = df.loc[i, col]\n",
    "                q = df.loc[j, col]\n",
    "                s.append(1 - abs(p - q)/(n - 1))\n",
    "            # compute magnitude of the similarity vector, normalize\n",
    "            mag = np.linalg.norm(s)/math.sqrt(8)\n",
    "            # compute magnitude of the disimilarity vector, normalize\n",
    "            magd = np.linalg.norm([(1 - x) for x in s ])/math.sqrt(8)\n",
    "            # insert into similarity matrix\n",
    "            simatrix[i][j] = mag\n",
    "            simatrix[j][i] = mag\n",
    "            # insert into dismatrix\n",
    "            dismatrix[i][j] = magd\n",
    "            dismatrix[j][i] = magd\n",
    "        simatrix[i][i] = 1\n",
    "        dismatrix[i][i] = 0\n",
    "    \n",
    "\n",
    "# compute and export the similarity matrix into a csv file\n",
    "metrics(df)\n",
    "pd.DataFrame(simatrix).to_csv('output/simatrix_200.csv', index=False)\n",
    "pd.DataFrame(dismatrix).to_csv('output/dismatrix_200.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMC to compute metrics\n",
    "treat all attributes as nominal attributes. Use SMC to do binary computation of similarity and disimilarity (distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...100...200...300...400...500...600...700...800...900...1000...1100...1200...1300...1400...1500...1600...1700...1800...1900...2000...2100...2200...2300...2400...2500...2600...2700...2800...2900...3000...3100...3200...3300...3400...3500...3600...3700...3800...3900...4000...4100...4200...4300...4400...4500...4600...4700..."
     ]
    }
   ],
   "source": [
    "# for testing purpose\n",
    "# df = df.head(200)\n",
    "\n",
    "columns = ['language', 'cast_0', 'director', 'genre_0', 'company_0', 'country', 'cast_num', 'crew_num']\n",
    "\n",
    "# similarity matrix\n",
    "simatrix = np.zeros((len(df), len(df)))\n",
    "# distance matrix\n",
    "dismatrix = np.zeros((len(df), len(df)))\n",
    "\n",
    "# simpler metrics computing method that only computes as nominal attribute\n",
    "def metrics_simple(df):\n",
    "    # for each row combination\n",
    "    for i in range(len(df) - 1):\n",
    "        for j in range(i + 1, len(df)):\n",
    "            # similarity vector of p and q\n",
    "            s = 0\n",
    "            # nominal\n",
    "            for col in columns:\n",
    "                p = df.loc[i, col]\n",
    "                q = df.loc[j, col]\n",
    "                if p == q:\n",
    "                    s += 1\n",
    "            # insert into similarity matrix\n",
    "            simatrix[i][j] = s/8\n",
    "            simatrix[j][i] = s/8\n",
    "            # insert into dismatrix\n",
    "            dismatrix[i][j] = (8-s)/8\n",
    "            dismatrix[j][i] = (8-s)/8\n",
    "        simatrix[i][i] = 1\n",
    "        dismatrix[i][i] = 0\n",
    "        if i%100 == 0:\n",
    "            print(i, end = '...')\n",
    "\n",
    "# compute and export the similarity matrix into a csv file\n",
    "metrics_simple(df)\n",
    "pd.DataFrame(simatrix).to_csv('output/simatrix.csv', index=False)\n",
    "pd.DataFrame(dismatrix).to_csv('output/dismatrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DBScan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How to determine eps and min_samples?<br>\n",
    "A low minPts means it will build more clusters from noise. One heuristic approach is use ln(n), where n is the total number of points to be clustered.\n",
    "2. To determine elipson:<br>\n",
    "<b>k-distance plot</b> <br>\n",
    "In a clustering with minPts = k, we expect that core pints and border points' k-distance are within a certain range, while noise points can have much greater k-distance, thus we can observe a knee point in the k-distance plot. However, sometimes there may be no obvious knee, or there can be multiple knees, which makes it hard to decide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.474285690404962"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dismatrix))\n",
    "np.log(4790)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=0.374\n",
      " [-1 -1 -1 -1 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  3 -1 -1 -1 -1\n",
      " -1 -1 -1 -1  1 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1]\n",
      "number of clusters:  13\n",
      "number of noises:  4015\n",
      "eps=0.375\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0 -1  0  0 -1  0\n",
      " -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0 -1  0\n",
      "  0 -1 -1  0]\n",
      "number of clusters:  1\n",
      "number of noises:  639\n",
      "eps=0.38\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0 -1  0  0 -1  0\n",
      " -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0 -1  0\n",
      "  0 -1 -1  0]\n",
      "number of clusters:  1\n",
      "number of noises:  639\n"
     ]
    }
   ],
   "source": [
    "# use disimatrix (distance) computed by nominal\n",
    "dbscan = DBSCAN(eps=0.374, min_samples=9, metric=\"precomputed\").fit_predict(dismatrix)\n",
    "print('eps=0.374\\n', dbscan[:100])\n",
    "print('number of clusters: ', max(dbscan) + 1)\n",
    "print('number of noises: ', len([x for x in dbscan if x == -1]))\n",
    "\n",
    "dbscan = DBSCAN(eps=0.375, min_samples=9, metric=\"precomputed\").fit_predict(dismatrix)\n",
    "print('eps=0.375\\n', dbscan[:100])\n",
    "print('number of clusters: ', max(dbscan) + 1)\n",
    "print('number of noises: ', len([x for x in dbscan if x == -1]))\n",
    "\n",
    "dbscan = DBSCAN(eps=0.38, min_samples=9, metric=\"precomputed\").fit_predict(dismatrix)\n",
    "print('eps=0.38\\n', dbscan[:100])\n",
    "print('number of clusters: ', max(dbscan) + 1)\n",
    "print('number of noises: ', len([x for x in dbscan if x == -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, values after 0.374 gives us one single big cluster. Our goal is to divide as much of the data into moderate number of clusters. If we can approach our goal to divide them into two reasonable clusters and fit into (popular, non-popular), it would be best.  \n",
    "<br>We choose eps = 0.374, then try different min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples=8\n",
      " [-1  1 -1 -1 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1 -1  3 -1 -1 -1 -1\n",
      " -1 -1 -1 -1  2 -1 -1  0 -1 -1  4 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1]\n",
      "number of clusters:  14\n",
      "number of noises:  3900\n",
      "min_samples=9\n",
      " [-1 -1 -1 -1 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  3 -1 -1 -1 -1\n",
      " -1 -1 -1 -1  1 -1 -1  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1]\n",
      "number of clusters:  12\n",
      "number of noises:  4015\n",
      "min_samples=10\n",
      " [-1 -1 -1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1  2 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1]\n",
      "number of clusters:  4\n",
      "number of noises:  4311\n"
     ]
    }
   ],
   "source": [
    "# use disimatrix (distance) computed by nominal\n",
    "dbscan = DBSCAN(eps=0.374, min_samples=8, metric=\"precomputed\").fit_predict(dismatrix)\n",
    "print('min_samples=8\\n', dbscan[:100])\n",
    "print('number of clusters: ', max(dbscan))\n",
    "print('number of noises: ', len([x for x in dbscan if x == -1]))\n",
    "\n",
    "dbscan = DBSCAN(eps=0.374, min_samples=9, metric=\"precomputed\").fit_predict(dismatrix)\n",
    "print('min_samples=9\\n', dbscan[:100])\n",
    "print('number of clusters: ', max(dbscan))\n",
    "print('number of noises: ', len([x for x in dbscan if x == -1]))\n",
    "\n",
    "dbscan = DBSCAN(eps=0.374, min_samples=13, metric=\"precomputed\").fit_predict(dismatrix)\n",
    "print('min_samples=10\\n', dbscan[:100])\n",
    "print('number of clusters: ', max(dbscan))\n",
    "print('number of noises: ', len([x for x in dbscan if x == -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, no matter which set of parameter we chose, clusering using DBSCAN gives us <b>too many noise points</b>.\n",
    "\n",
    "### Conclusion:\n",
    "<br>DBSCAN is not a good method to cluster our dataset. The reason might be that the features in our dataset are mostly categorical instead of numerical. And when computing similarity, SMC is used. The dissimilarity is used as disttance. However, it is not strictly a metric because it does not satisfy <b>Triangle Inequality</b>.\n",
    "<br>The dataset have both high density and low density. The rather low density data are all mistaken as noise points.\n",
    "<br>To sum up, DBSCAN, a clustering method used to separate clusters of high density from noise points, is not suitable for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
